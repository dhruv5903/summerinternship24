{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "13IRDMtEluBfTb67z5FtrMsRtKm5DEMRY",
      "authorship_tag": "ABX9TyO1B1av0Frk90LUdHlYXTbx",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dhruv5903/summerinternship24/blob/main/NgramModels(Final).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fLyw98q4840Z",
        "outputId": "a0aefa84-f26d-4f72-dfa9-0c2d3cce0aa2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4000\n"
          ]
        }
      ],
      "source": [
        "file=open(\"/content/drive/MyDrive/TEXTCORPUS.txt\",\"r\")\n",
        "readcorpus=file.read()\n",
        "print(len(readcorpus))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ojOvFLTl6wyY",
        "outputId": "5d444eee-ee6f-425c-cc2d-bd10d5eb8a16"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('all')\n",
        "from nltk.tokenize import word_tokenize,sent_tokenize"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gIxIleX0-IF4",
        "outputId": "ed8529af-3857-41a1-a3f1-4eea755c95ab"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading collection 'all'\n",
            "[nltk_data]    | \n",
            "[nltk_data]    | Downloading package abc to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/abc.zip.\n",
            "[nltk_data]    | Downloading package alpino to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/alpino.zip.\n",
            "[nltk_data]    | Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping taggers/averaged_perceptron_tagger.zip.\n",
            "[nltk_data]    | Downloading package averaged_perceptron_tagger_ru to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping\n",
            "[nltk_data]    |       taggers/averaged_perceptron_tagger_ru.zip.\n",
            "[nltk_data]    | Downloading package basque_grammars to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping grammars/basque_grammars.zip.\n",
            "[nltk_data]    | Downloading package bcp47 to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package biocreative_ppi to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/biocreative_ppi.zip.\n",
            "[nltk_data]    | Downloading package bllip_wsj_no_aux to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping models/bllip_wsj_no_aux.zip.\n",
            "[nltk_data]    | Downloading package book_grammars to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping grammars/book_grammars.zip.\n",
            "[nltk_data]    | Downloading package brown to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/brown.zip.\n",
            "[nltk_data]    | Downloading package brown_tei to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/brown_tei.zip.\n",
            "[nltk_data]    | Downloading package cess_cat to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/cess_cat.zip.\n",
            "[nltk_data]    | Downloading package cess_esp to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/cess_esp.zip.\n",
            "[nltk_data]    | Downloading package chat80 to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/chat80.zip.\n",
            "[nltk_data]    | Downloading package city_database to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/city_database.zip.\n",
            "[nltk_data]    | Downloading package cmudict to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/cmudict.zip.\n",
            "[nltk_data]    | Downloading package comparative_sentences to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/comparative_sentences.zip.\n",
            "[nltk_data]    | Downloading package comtrans to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package conll2000 to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/conll2000.zip.\n",
            "[nltk_data]    | Downloading package conll2002 to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/conll2002.zip.\n",
            "[nltk_data]    | Downloading package conll2007 to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package crubadan to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/crubadan.zip.\n",
            "[nltk_data]    | Downloading package dependency_treebank to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/dependency_treebank.zip.\n",
            "[nltk_data]    | Downloading package dolch to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/dolch.zip.\n",
            "[nltk_data]    | Downloading package europarl_raw to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/europarl_raw.zip.\n",
            "[nltk_data]    | Downloading package extended_omw to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    | Downloading package floresta to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/floresta.zip.\n",
            "[nltk_data]    | Downloading package framenet_v15 to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/framenet_v15.zip.\n",
            "[nltk_data]    | Downloading package framenet_v17 to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/framenet_v17.zip.\n",
            "[nltk_data]    | Downloading package gazetteers to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/gazetteers.zip.\n",
            "[nltk_data]    | Downloading package genesis to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/genesis.zip.\n",
            "[nltk_data]    | Downloading package gutenberg to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/gutenberg.zip.\n",
            "[nltk_data]    | Downloading package ieer to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/ieer.zip.\n",
            "[nltk_data]    | Downloading package inaugural to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/inaugural.zip.\n",
            "[nltk_data]    | Downloading package indian to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/indian.zip.\n",
            "[nltk_data]    | Downloading package jeita to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package kimmo to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/kimmo.zip.\n",
            "[nltk_data]    | Downloading package knbc to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package large_grammars to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping grammars/large_grammars.zip.\n",
            "[nltk_data]    | Downloading package lin_thesaurus to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/lin_thesaurus.zip.\n",
            "[nltk_data]    | Downloading package mac_morpho to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/mac_morpho.zip.\n",
            "[nltk_data]    | Downloading package machado to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package masc_tagged to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package maxent_ne_chunker to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping chunkers/maxent_ne_chunker.zip.\n",
            "[nltk_data]    | Downloading package maxent_treebank_pos_tagger to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping taggers/maxent_treebank_pos_tagger.zip.\n",
            "[nltk_data]    | Downloading package moses_sample to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping models/moses_sample.zip.\n",
            "[nltk_data]    | Downloading package movie_reviews to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/movie_reviews.zip.\n",
            "[nltk_data]    | Downloading package mte_teip5 to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/mte_teip5.zip.\n",
            "[nltk_data]    | Downloading package mwa_ppdb to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping misc/mwa_ppdb.zip.\n",
            "[nltk_data]    | Downloading package names to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/names.zip.\n",
            "[nltk_data]    | Downloading package nombank.1.0 to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package nonbreaking_prefixes to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/nonbreaking_prefixes.zip.\n",
            "[nltk_data]    | Downloading package nps_chat to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/nps_chat.zip.\n",
            "[nltk_data]    | Downloading package omw to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package omw-1.4 to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package opinion_lexicon to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/opinion_lexicon.zip.\n",
            "[nltk_data]    | Downloading package panlex_swadesh to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    | Downloading package paradigms to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/paradigms.zip.\n",
            "[nltk_data]    | Downloading package pe08 to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/pe08.zip.\n",
            "[nltk_data]    | Downloading package perluniprops to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping misc/perluniprops.zip.\n",
            "[nltk_data]    | Downloading package pil to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/pil.zip.\n",
            "[nltk_data]    | Downloading package pl196x to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/pl196x.zip.\n",
            "[nltk_data]    | Downloading package porter_test to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping stemmers/porter_test.zip.\n",
            "[nltk_data]    | Downloading package ppattach to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/ppattach.zip.\n",
            "[nltk_data]    | Downloading package problem_reports to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/problem_reports.zip.\n",
            "[nltk_data]    | Downloading package product_reviews_1 to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/product_reviews_1.zip.\n",
            "[nltk_data]    | Downloading package product_reviews_2 to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/product_reviews_2.zip.\n",
            "[nltk_data]    | Downloading package propbank to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package pros_cons to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/pros_cons.zip.\n",
            "[nltk_data]    | Downloading package ptb to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/ptb.zip.\n",
            "[nltk_data]    | Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data]    | Downloading package qc to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/qc.zip.\n",
            "[nltk_data]    | Downloading package reuters to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package rslp to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping stemmers/rslp.zip.\n",
            "[nltk_data]    | Downloading package rte to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/rte.zip.\n",
            "[nltk_data]    | Downloading package sample_grammars to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping grammars/sample_grammars.zip.\n",
            "[nltk_data]    | Downloading package semcor to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package senseval to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/senseval.zip.\n",
            "[nltk_data]    | Downloading package sentence_polarity to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/sentence_polarity.zip.\n",
            "[nltk_data]    | Downloading package sentiwordnet to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/sentiwordnet.zip.\n",
            "[nltk_data]    | Downloading package shakespeare to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/shakespeare.zip.\n",
            "[nltk_data]    | Downloading package sinica_treebank to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/sinica_treebank.zip.\n",
            "[nltk_data]    | Downloading package smultron to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/smultron.zip.\n",
            "[nltk_data]    | Downloading package snowball_data to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    | Downloading package spanish_grammars to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping grammars/spanish_grammars.zip.\n",
            "[nltk_data]    | Downloading package state_union to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/state_union.zip.\n",
            "[nltk_data]    | Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data]    | Downloading package subjectivity to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/subjectivity.zip.\n",
            "[nltk_data]    | Downloading package swadesh to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/swadesh.zip.\n",
            "[nltk_data]    | Downloading package switchboard to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/switchboard.zip.\n",
            "[nltk_data]    | Downloading package tagsets to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping help/tagsets.zip.\n",
            "[nltk_data]    | Downloading package timit to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/timit.zip.\n",
            "[nltk_data]    | Downloading package toolbox to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/toolbox.zip.\n",
            "[nltk_data]    | Downloading package treebank to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/treebank.zip.\n",
            "[nltk_data]    | Downloading package twitter_samples to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/twitter_samples.zip.\n",
            "[nltk_data]    | Downloading package udhr to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/udhr.zip.\n",
            "[nltk_data]    | Downloading package udhr2 to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/udhr2.zip.\n",
            "[nltk_data]    | Downloading package unicode_samples to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/unicode_samples.zip.\n",
            "[nltk_data]    | Downloading package universal_tagset to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping taggers/universal_tagset.zip.\n",
            "[nltk_data]    | Downloading package universal_treebanks_v20 to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    | Downloading package vader_lexicon to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    | Downloading package verbnet to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/verbnet.zip.\n",
            "[nltk_data]    | Downloading package verbnet3 to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/verbnet3.zip.\n",
            "[nltk_data]    | Downloading package webtext to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/webtext.zip.\n",
            "[nltk_data]    | Downloading package wmt15_eval to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping models/wmt15_eval.zip.\n",
            "[nltk_data]    | Downloading package word2vec_sample to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping models/word2vec_sample.zip.\n",
            "[nltk_data]    | Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package wordnet2021 to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package wordnet2022 to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/wordnet2022.zip.\n",
            "[nltk_data]    | Downloading package wordnet31 to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package wordnet_ic to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/wordnet_ic.zip.\n",
            "[nltk_data]    | Downloading package words to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/words.zip.\n",
            "[nltk_data]    | Downloading package ycoe to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/ycoe.zip.\n",
            "[nltk_data]    | \n",
            "[nltk_data]  Done downloading collection all\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import string\n",
        "string.punctuation = string.punctuation +'“'+'”'+'-'+'’'+'‘'+'—'\n",
        "string.punctuation = string.punctuation.replace('.', '')\n",
        "file = open('/content/drive/MyDrive/TEXTCORPUS.txt','r').read()\n",
        "#preprocess data to remove newlines and special characters\n",
        "file_new = \"\"\n",
        "for line in file:\n",
        "    line_new = line.replace(\"\\n\", \" \")\n",
        "    file_new += line_new\n",
        "preprocessedCorpus = \"\".join([char for char in file_new if char not in string.punctuation])"
      ],
      "metadata": {
        "id": "87tQ7iYpAmss"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "file=open(\"/content/drive/MyDrive/TEXTCORPUS.txt\",\"r\")\n",
        "readcorpus=file.read()\n",
        "print(readcorpus)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qy0gFZia8ReN",
        "outputId": "ea48aec0-e43a-4238-f589-5f6081d53d79"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The room in which the boys were fed, was a large stone hall, with a copper [a large, heated copper pot] at one end: out of which the master, dressed in an apron for the purpose, and assisted by one or two women, ladled the gruel [a watery cereal like very thin oatmeal] at mealtimes. Of this festive composition each boy had one porringer [small bowl], and no more—except on occasions of great public rejoicing, when he had two ounces and a quarter of bread besides. The bowls never wanted washing. The boys polished them with their spoons till they shone again; and when they had performed this operation (which never took very long, the spoons being nearly as large as the bowls), they would sit staring at the copper, with such eager eyes, as if they could have devoured the very bricks of which it was composed; employing themselves, meanwhile, in sucking their fingers most assiduously [diligently], with the view of catching up any stray splashes of gruel that  ight have been cast thereon. Boys have generally excellent appetites. Oliver Twist and his companions suffered the  ortures of slow starvation for three months: at last they got so voracious and wild with hunger, that one boy, who was tall for his age, and hadn’t been used to that sort of thing (for his father had kept a small cook-shop), hinted darkly to his companions, that unless he had another basin of gruel per diem [each day], he was afraid he might some night happen to eat the boy who slept next him, who happened to be a weakly youth of tender age. He had a wild, hungry eye; and they implicitly believed him. A council was held; lots [objects, such as straws, that would be taken out of a container to make a decision or choice] were cast who should walk up to the master after supper that evening, and ask for more; and it fell to Oliver Twist. The evening arrived; the boys took their places. The master, in his cook’s uniform, stationed himself at the copper; his pauper [poor] assistants ranged themselves behind him; the gruel was served out; and a long grace was said over the short commons. The gruel disappeared; the boys whispered each other, and winked at Oliver; while his next neighbors nudged him. Child as he was, he was desperate with hunger, and reckless with misery. He rose from the table; and advancing to the master, basin and spoon in hand, said: somewhat alarmed at his own temerity [bravery]: “Please, sir, I want some more.” The master was a fat, healthy man; but he  turned very pale. He gazed in stupefied astonishment on the small rebel for some seconds, and then clung for support to the copper. The assistants were paralysed with wonder; the boys with fear. “What!” said the master at length, in a faint voice. “Please, sir,” replied Oliver, “I want some more.” The master aimed a blow at Oliver’s head with the ladle; pinioned [trapped] him in his arm; and shrieked aloud for the beadle [an official]. The board were sitting in solemn conclave [meeting], when Mr. Bumble rushed into the room in great excitement, and addressing the gentleman in the high chair, said, “Mr. Limbkins, I beg your pardon, sir! Oliver Twist has asked for more!” There was a general start. Horror was depicted on every countenance [face]. “For more!” said Mr. Limbkins. “Compose yourself, Bumble, and answer me distinctly [clearly]. Do I understand that he asked for more, after he had eaten the supper allotted by the dietary?” “He did, sir,” replied Bumble. “That boy will be hung,” said the gentleman in the white waistcoat. “I know that boy will be hung.” Nobody controverted [argued with] the prophetic gentleman’s opinion. An animated discussion took place. Oliver was ordered into instant confinement; and a bill was next morning pasted on the outside of the gate, offering a reward of five pounds to anybody who would take Oliver Twist off the hands of the parish. In other words, five pounds and Oliver Twist were offered to any man or woman who wanted an apprentice to any trade, business, or calling.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sentences = sent_tokenize(preprocessedCorpus)\n",
        "print(\"1st 5 sentences of preprocessed corpus are : \")\n",
        "print(sentences[0:5])\n",
        "words = word_tokenize(preprocessedCorpus)\n",
        "print(\"1st 5 words/tokens of preprocessed corpus are : \")\n",
        "print(words[0:5])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MQEbpMRI88yA",
        "outputId": "9af4b1a6-4c8c-4005-acee-437805512f8f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1st 5 sentences of preprocessed corpus are : \n",
            "['The room in which the boys were fed was a large stone hall with a copper a large heated copper pot at one end out of which the master dressed in an apron for the purpose and assisted by one or two women ladled the gruel a watery cereal like very thin oatmeal at mealtimes.', 'Of this festive composition each boy had one porringer small bowl and no moreexcept on occasions of great public rejoicing when he had two ounces and a quarter of bread besides.', 'The bowls never wanted washing.', 'The boys polished them with their spoons till they shone again and when they had performed this operation which never took very long the spoons being nearly as large as the bowls they would sit staring at the copper with such eager eyes as if they could have devoured the very bricks of which it was composed employing themselves meanwhile in sucking their fingers most assiduously diligently with the view of catching up any stray splashes of gruel that  ight have been cast thereon.', 'Boys have generally excellent appetites.']\n",
            "1st 5 words/tokens of preprocessed corpus are : \n",
            "['The', 'room', 'in', 'which', 'the']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('stopwords')\n",
        "from nltk.corpus import stopwords\n",
        "stop_words = set(stopwords.words('english'))\n",
        "filtered_tokens = [w for w in words if not w.lower() in stop_words]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7DUNb6V_BVB7",
        "outputId": "28687c0e-1104-4c54-f601-4b5a662a5095"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(filtered_tokens)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_Kp9RFHRBi1y",
        "outputId": "2f799253-df04-4e56-a9f4-dfbade14fed6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['room', 'boys', 'fed', 'large', 'stone', 'hall', 'copper', 'large', 'heated', 'copper', 'pot', 'one', 'end', 'master', 'dressed', 'apron', 'purpose', 'assisted', 'one', 'two', 'women', 'ladled', 'gruel', 'watery', 'cereal', 'like', 'thin', 'oatmeal', 'mealtimes', '.', 'festive', 'composition', 'boy', 'one', 'porringer', 'small', 'bowl', 'moreexcept', 'occasions', 'great', 'public', 'rejoicing', 'two', 'ounces', 'quarter', 'bread', 'besides', '.', 'bowls', 'never', 'wanted', 'washing', '.', 'boys', 'polished', 'spoons', 'till', 'shone', 'performed', 'operation', 'never', 'took', 'long', 'spoons', 'nearly', 'large', 'bowls', 'would', 'sit', 'staring', 'copper', 'eager', 'eyes', 'could', 'devoured', 'bricks', 'composed', 'employing', 'meanwhile', 'sucking', 'fingers', 'assiduously', 'diligently', 'view', 'catching', 'stray', 'splashes', 'gruel', 'ight', 'cast', 'thereon', '.', 'Boys', 'generally', 'excellent', 'appetites', '.', 'Oliver', 'Twist', 'companions', 'suffered', 'ortures', 'slow', 'starvation', 'three', 'months', 'last', 'got', 'voracious', 'wild', 'hunger', 'one', 'boy', 'tall', 'age', 'hadnt', 'used', 'sort', 'thing', 'father', 'kept', 'small', 'cookshop', 'hinted', 'darkly', 'companions', 'unless', 'another', 'basin', 'gruel', 'per', 'diem', 'day', 'afraid', 'might', 'night', 'happen', 'eat', 'boy', 'slept', 'next', 'happened', 'weakly', 'youth', 'tender', 'age', '.', 'wild', 'hungry', 'eye', 'implicitly', 'believed', '.', 'council', 'held', 'lots', 'objects', 'straws', 'would', 'taken', 'container', 'make', 'decision', 'choice', 'cast', 'walk', 'master', 'supper', 'evening', 'ask', 'fell', 'Oliver', 'Twist', '.', 'evening', 'arrived', 'boys', 'took', 'places', '.', 'master', 'cooks', 'uniform', 'stationed', 'copper', 'pauper', 'poor', 'assistants', 'ranged', 'behind', 'gruel', 'served', 'long', 'grace', 'said', 'short', 'commons', '.', 'gruel', 'disappeared', 'boys', 'whispered', 'winked', 'Oliver', 'next', 'neighbors', 'nudged', '.', 'Child', 'desperate', 'hunger', 'reckless', 'misery', '.', 'rose', 'table', 'advancing', 'master', 'basin', 'spoon', 'hand', 'said', 'somewhat', 'alarmed', 'temerity', 'bravery', 'Please', 'sir', 'want', '.', 'master', 'fat', 'healthy', 'man', 'turned', 'pale', '.', 'gazed', 'stupefied', 'astonishment', 'small', 'rebel', 'seconds', 'clung', 'support', 'copper', '.', 'assistants', 'paralysed', 'wonder', 'boys', 'fear', '.', 'said', 'master', 'length', 'faint', 'voice', '.', 'Please', 'sir', 'replied', 'Oliver', 'want', '.', 'master', 'aimed', 'blow', 'Olivers', 'head', 'ladle', 'pinioned', 'trapped', 'arm', 'shrieked', 'aloud', 'beadle', 'official', '.', 'board', 'sitting', 'solemn', 'conclave', 'meeting', 'Mr.', 'Bumble', 'rushed', 'room', 'great', 'excitement', 'addressing', 'gentleman', 'high', 'chair', 'said', 'Mr.', 'Limbkins', 'beg', 'pardon', 'sir', 'Oliver', 'Twist', 'asked', 'general', 'start', '.', 'Horror', 'depicted', 'every', 'countenance', 'face', '.', 'said', 'Mr.', 'Limbkins', '.', 'Compose', 'Bumble', 'answer', 'distinctly', 'clearly', '.', 'understand', 'asked', 'eaten', 'supper', 'allotted', 'dietary', 'sir', 'replied', 'Bumble', '.', 'boy', 'hung', 'said', 'gentleman', 'white', 'waistcoat', '.', 'know', 'boy', 'hung', '.', 'Nobody', 'controverted', 'argued', 'prophetic', 'gentlemans', 'opinion', '.', 'animated', 'discussion', 'took', 'place', '.', 'Oliver', 'ordered', 'instant', 'confinement', 'bill', 'next', 'morning', 'pasted', 'outside', 'gate', 'offering', 'reward', 'five', 'pounds', 'anybody', 'would', 'take', 'Oliver', 'Twist', 'hands', 'parish', '.', 'words', 'five', 'pounds', 'Oliver', 'Twist', 'offered', 'man', 'woman', 'wanted', 'apprentice', 'trade', 'business', 'calling', '.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import Counter\n",
        "from nltk.util import ngrams\n",
        "unigrams=[]\n",
        "bigrams=[]\n",
        "trigrams=[]\n",
        "for content in (sentences):\n",
        "    content = content.lower()\n",
        "    content = word_tokenize(content)\n",
        "    for word in content:\n",
        "        if (word =='.'):\n",
        "            content.remove(word)\n",
        "        else:\n",
        "            unigrams.append(word)\n",
        "    bigrams.extend(ngrams(content,2))\n",
        "    trigrams.extend(ngrams(content,3))\n",
        "print (\"Frist 5 Sample of Unigrams: \\n\" + str(unigrams[:5]))\n",
        "print (\"Frist 5 Sample of Bigrams: \\n\" + str(bigrams[:5]))\n",
        "print (\"Frist 5 Sample of Trigrams: \\n\" + str(trigrams[:5]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0H5m-HNqBldK",
        "outputId": "d89cb9b0-0e2d-4a07-eff9-6c857f09367b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Frist 5 Sample of Unigrams: \n",
            "['the', 'room', 'in', 'which', 'the']\n",
            "Frist 5 Sample of Bigrams: \n",
            "[('the', 'room'), ('room', 'in'), ('in', 'which'), ('which', 'the'), ('the', 'boys')]\n",
            "Frist 5 Sample of Trigrams: \n",
            "[('the', 'room', 'in'), ('room', 'in', 'which'), ('in', 'which', 'the'), ('which', 'the', 'boys'), ('the', 'boys', 'were')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def stopwords_removal(n, a):\n",
        "    b = []\n",
        "    if n == 1:\n",
        "        for word in a:\n",
        "            count = 0\n",
        "            if word in stop_words:\n",
        "                count = 0\n",
        "            else:\n",
        "                count = 1\n",
        "            if (count==1):\n",
        "                b.append(word)\n",
        "        return(b)\n",
        "    else:\n",
        "        for pair in a:\n",
        "            count = 0\n",
        "            for word in pair:\n",
        "                if word in stop_words:\n",
        "                    count = count or 0\n",
        "                else:\n",
        "                    count = count or 1\n",
        "            if (count==1):\n",
        "                b.append(pair)\n",
        "        return(b)\n",
        "unigrams_Processed = stopwords_removal(1,unigrams)\n",
        "bigrams_Processed = stopwords_removal(2,bigrams)\n",
        "trigrams_Processed = stopwords_removal(3,trigrams)\n",
        "print (\"First 5 sample of unigram after processing:\\n\"+str(unigrams_Processed[:5]))\n",
        "print (\"First 5 sample of bigram after processing:\\n\"+str(bigrams_Processed[:5]))\n",
        "print (\"First 5 sample of trigram after processing:\\n\"+str(trigrams_Processed[:5]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RRx4IB8bFA0N",
        "outputId": "9d66d289-16a4-4807-a5ef-6895832dc179"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "First 5 sample of unigram after processing:\n",
            "['room', 'boys', 'fed', 'large', 'stone']\n",
            "First 5 sample of bigram after processing:\n",
            "[('the', 'room'), ('room', 'in'), ('the', 'boys'), ('boys', 'were'), ('were', 'fed')]\n",
            "First 5 sample of trigram after processing:\n",
            "[('the', 'room', 'in'), ('room', 'in', 'which'), ('which', 'the', 'boys'), ('the', 'boys', 'were'), ('boys', 'were', 'fed')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def ngrams_freq(n, ngramList):\n",
        "    ngram_freq_dict = {}\n",
        "    for ngram in ngramList:\n",
        "        if ngram in ngram_freq_dict:\n",
        "            ngram_freq_dict[ngram] += 1\n",
        "        else:\n",
        "            ngram_freq_dict[ngram] = 1\n",
        "    return ngram_freq_dict\n",
        "unigrams_freqDist = ngrams_freq(1, unigrams)\n",
        "unigrams_Processed_freqDist = ngrams_freq(1, unigrams_Processed)\n",
        "bigrams_freqDist = ngrams_freq(2, bigrams)\n",
        "bigrams_Processed_freqDist = ngrams_freq(2, bigrams_Processed)\n",
        "trigrams_freqDist = ngrams_freq(3, trigrams)\n",
        "trigrams_Processed_freqDist = ngrams_freq(3, trigrams_Processed)"
      ],
      "metadata": {
        "id": "R9ExEjecRPxs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(unigrams_Processed_freqDist)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tCE0f70cSIXp",
        "outputId": "c985d175-2f3f-44c7-afbc-402cb5cfc1cf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'room': 2, 'boys': 6, 'fed': 1, 'large': 3, 'stone': 1, 'hall': 1, 'copper': 5, 'heated': 1, 'pot': 1, 'one': 4, 'end': 1, 'master': 7, 'dressed': 1, 'apron': 1, 'purpose': 1, 'assisted': 1, 'two': 2, 'women': 1, 'ladled': 1, 'gruel': 5, 'watery': 1, 'cereal': 1, 'like': 1, 'thin': 1, 'oatmeal': 1, 'mealtimes': 1, 'festive': 1, 'composition': 1, 'boy': 5, 'porringer': 1, 'small': 3, 'bowl': 1, 'moreexcept': 1, 'occasions': 1, 'great': 2, 'public': 1, 'rejoicing': 1, 'ounces': 1, 'quarter': 1, 'bread': 1, 'besides': 1, 'bowls': 2, 'never': 2, 'wanted': 2, 'washing': 1, 'polished': 1, 'spoons': 2, 'till': 1, 'shone': 1, 'performed': 1, 'operation': 1, 'took': 3, 'long': 2, 'nearly': 1, 'would': 3, 'sit': 1, 'staring': 1, 'eager': 1, 'eyes': 1, 'could': 1, 'devoured': 1, 'bricks': 1, 'composed': 1, 'employing': 1, 'meanwhile': 1, 'sucking': 1, 'fingers': 1, 'assiduously': 1, 'diligently': 1, 'view': 1, 'catching': 1, 'stray': 1, 'splashes': 1, 'ight': 1, 'cast': 2, 'thereon': 1, 'generally': 1, 'excellent': 1, 'appetites': 1, 'oliver': 8, 'twist': 5, 'companions': 2, 'suffered': 1, 'ortures': 1, 'slow': 1, 'starvation': 1, 'three': 1, 'months': 1, 'last': 1, 'got': 1, 'voracious': 1, 'wild': 2, 'hunger': 2, 'tall': 1, 'age': 2, 'hadnt': 1, 'used': 1, 'sort': 1, 'thing': 1, 'father': 1, 'kept': 1, 'cookshop': 1, 'hinted': 1, 'darkly': 1, 'unless': 1, 'another': 1, 'basin': 2, 'per': 1, 'diem': 1, 'day': 1, 'afraid': 1, 'might': 1, 'night': 1, 'happen': 1, 'eat': 1, 'slept': 1, 'next': 3, 'happened': 1, 'weakly': 1, 'youth': 1, 'tender': 1, 'hungry': 1, 'eye': 1, 'implicitly': 1, 'believed': 1, 'council': 1, 'held': 1, 'lots': 1, 'objects': 1, 'straws': 1, 'taken': 1, 'container': 1, 'make': 1, 'decision': 1, 'choice': 1, 'walk': 1, 'supper': 2, 'evening': 2, 'ask': 1, 'fell': 1, 'arrived': 1, 'places': 1, 'cooks': 1, 'uniform': 1, 'stationed': 1, 'pauper': 1, 'poor': 1, 'assistants': 2, 'ranged': 1, 'behind': 1, 'served': 1, 'grace': 1, 'said': 6, 'short': 1, 'commons': 1, 'disappeared': 1, 'whispered': 1, 'winked': 1, 'neighbors': 1, 'nudged': 1, 'child': 1, 'desperate': 1, 'reckless': 1, 'misery': 1, 'rose': 1, 'table': 1, 'advancing': 1, 'spoon': 1, 'hand': 1, 'somewhat': 1, 'alarmed': 1, 'temerity': 1, 'bravery': 1, 'please': 2, 'sir': 4, 'want': 2, 'fat': 1, 'healthy': 1, 'man': 2, 'turned': 1, 'pale': 1, 'gazed': 1, 'stupefied': 1, 'astonishment': 1, 'rebel': 1, 'seconds': 1, 'clung': 1, 'support': 1, 'paralysed': 1, 'wonder': 1, 'fear': 1, 'length': 1, 'faint': 1, 'voice': 1, 'replied': 2, 'aimed': 1, 'blow': 1, 'olivers': 1, 'head': 1, 'ladle': 1, 'pinioned': 1, 'trapped': 1, 'arm': 1, 'shrieked': 1, 'aloud': 1, 'beadle': 1, 'official': 1, 'board': 1, 'sitting': 1, 'solemn': 1, 'conclave': 1, 'meeting': 1, 'mr.': 3, 'bumble': 3, 'rushed': 1, 'excitement': 1, 'addressing': 1, 'gentleman': 2, 'high': 1, 'chair': 1, 'limbkins': 2, 'beg': 1, 'pardon': 1, 'asked': 2, 'general': 1, 'start': 1, 'horror': 1, 'depicted': 1, 'every': 1, 'countenance': 1, 'face': 1, 'compose': 1, 'answer': 1, 'distinctly': 1, 'clearly': 1, 'understand': 1, 'eaten': 1, 'allotted': 1, 'dietary': 1, 'hung': 2, 'white': 1, 'waistcoat': 1, 'know': 1, 'nobody': 1, 'controverted': 1, 'argued': 1, 'prophetic': 1, 'gentlemans': 1, 'opinion': 1, 'animated': 1, 'discussion': 1, 'place': 1, 'ordered': 1, 'instant': 1, 'confinement': 1, 'bill': 1, 'morning': 1, 'pasted': 1, 'outside': 1, 'gate': 1, 'offering': 1, 'reward': 1, 'five': 2, 'pounds': 2, 'anybody': 1, 'take': 1, 'hands': 1, 'parish': 1, 'words': 1, 'offered': 1, 'woman': 1, 'apprentice': 1, 'trade': 1, 'business': 1, 'calling': 1}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "smoothed_bigrams_probDist = {}\n",
        "V = len(unigrams_freqDist)\n",
        "for i in bigrams_freqDist:\n",
        "    smoothed_bigrams_probDist[i] = (bigrams_freqDist[i] + 1)/(unigrams_freqDist[i[0]]+V)\n",
        "smoothed_trigrams_probDist = {}\n",
        "for i in trigrams_freqDist:\n",
        "    smoothed_trigrams_probDist[i] = (trigrams_freqDist[i] + 1)/(bigrams_freqDist[i[0:2]]+V)"
      ],
      "metadata": {
        "id": "r00Oy723SM_X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(smoothed_trigrams_probDist)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P3aepckm7jH2",
        "outputId": "cde3631a-0c09-4d67-a489-f51aa8d2f020"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{('the', 'room', 'in'): 0.008670520231213872, ('room', 'in', 'which'): 0.005780346820809248, ('in', 'which', 'the'): 0.005797101449275362, ('which', 'the', 'boys'): 0.005780346820809248, ('the', 'boys', 'were'): 0.0057306590257879654, ('boys', 'were', 'fed'): 0.005797101449275362, ('were', 'fed', 'was'): 0.005797101449275362, ('fed', 'was', 'a'): 0.005797101449275362, ('was', 'a', 'large'): 0.005763688760806916, ('a', 'large', 'stone'): 0.005780346820809248, ('large', 'stone', 'hall'): 0.005797101449275362, ('stone', 'hall', 'with'): 0.005797101449275362, ('hall', 'with', 'a'): 0.005797101449275362, ('with', 'a', 'copper'): 0.005797101449275362, ('a', 'copper', 'a'): 0.005797101449275362, ('copper', 'a', 'large'): 0.005797101449275362, ('a', 'large', 'heated'): 0.005780346820809248, ('large', 'heated', 'copper'): 0.005797101449275362, ('heated', 'copper', 'pot'): 0.005797101449275362, ('copper', 'pot', 'at'): 0.005797101449275362, ('pot', 'at', 'one'): 0.005797101449275362, ('at', 'one', 'end'): 0.005797101449275362, ('one', 'end', 'out'): 0.005797101449275362, ('end', 'out', 'of'): 0.005797101449275362, ('out', 'of', 'which'): 0.005780346820809248, ('of', 'which', 'the'): 0.005780346820809248, ('which', 'the', 'master'): 0.005780346820809248, ('the', 'master', 'dressed'): 0.005698005698005698, ('master', 'dressed', 'in'): 0.005797101449275362, ('dressed', 'in', 'an'): 0.005797101449275362, ('in', 'an', 'apron'): 0.005797101449275362, ('an', 'apron', 'for'): 0.005797101449275362, ('apron', 'for', 'the'): 0.005797101449275362, ('for', 'the', 'purpose'): 0.005780346820809248, ('the', 'purpose', 'and'): 0.005797101449275362, ('purpose', 'and', 'assisted'): 0.005797101449275362, ('and', 'assisted', 'by'): 0.005797101449275362, ('assisted', 'by', 'one'): 0.005797101449275362, ('by', 'one', 'or'): 0.005797101449275362, ('one', 'or', 'two'): 0.005797101449275362, ('or', 'two', 'women'): 0.005797101449275362, ('two', 'women', 'ladled'): 0.005797101449275362, ('women', 'ladled', 'the'): 0.005797101449275362, ('ladled', 'the', 'gruel'): 0.005797101449275362, ('the', 'gruel', 'a'): 0.005763688760806916, ('gruel', 'a', 'watery'): 0.005797101449275362, ('a', 'watery', 'cereal'): 0.005797101449275362, ('watery', 'cereal', 'like'): 0.005797101449275362, ('cereal', 'like', 'very'): 0.005797101449275362, ('like', 'very', 'thin'): 0.005797101449275362, ('very', 'thin', 'oatmeal'): 0.005797101449275362, ('thin', 'oatmeal', 'at'): 0.005797101449275362, ('oatmeal', 'at', 'mealtimes'): 0.005797101449275362, ('of', 'this', 'festive'): 0.005797101449275362, ('this', 'festive', 'composition'): 0.005797101449275362, ('festive', 'composition', 'each'): 0.005797101449275362, ('composition', 'each', 'boy'): 0.005797101449275362, ('each', 'boy', 'had'): 0.005797101449275362, ('boy', 'had', 'one'): 0.005797101449275362, ('had', 'one', 'porringer'): 0.005797101449275362, ('one', 'porringer', 'small'): 0.005797101449275362, ('porringer', 'small', 'bowl'): 0.005797101449275362, ('small', 'bowl', 'and'): 0.005797101449275362, ('bowl', 'and', 'no'): 0.005797101449275362, ('and', 'no', 'moreexcept'): 0.005797101449275362, ('no', 'moreexcept', 'on'): 0.005797101449275362, ('moreexcept', 'on', 'occasions'): 0.005797101449275362, ('on', 'occasions', 'of'): 0.005797101449275362, ('occasions', 'of', 'great'): 0.005797101449275362, ('of', 'great', 'public'): 0.005797101449275362, ('great', 'public', 'rejoicing'): 0.005797101449275362, ('public', 'rejoicing', 'when'): 0.005797101449275362, ('rejoicing', 'when', 'he'): 0.005797101449275362, ('when', 'he', 'had'): 0.005797101449275362, ('he', 'had', 'two'): 0.005747126436781609, ('had', 'two', 'ounces'): 0.005797101449275362, ('two', 'ounces', 'and'): 0.005797101449275362, ('ounces', 'and', 'a'): 0.005797101449275362, ('and', 'a', 'quarter'): 0.005763688760806916, ('a', 'quarter', 'of'): 0.005797101449275362, ('quarter', 'of', 'bread'): 0.005797101449275362, ('of', 'bread', 'besides'): 0.005797101449275362, ('the', 'bowls', 'never'): 0.005780346820809248, ('bowls', 'never', 'wanted'): 0.005797101449275362, ('never', 'wanted', 'washing'): 0.005797101449275362, ('the', 'boys', 'polished'): 0.0057306590257879654, ('boys', 'polished', 'them'): 0.005797101449275362, ('polished', 'them', 'with'): 0.005797101449275362, ('them', 'with', 'their'): 0.005797101449275362, ('with', 'their', 'spoons'): 0.005797101449275362, ('their', 'spoons', 'till'): 0.005797101449275362, ('spoons', 'till', 'they'): 0.005797101449275362, ('till', 'they', 'shone'): 0.005797101449275362, ('they', 'shone', 'again'): 0.005797101449275362, ('shone', 'again', 'and'): 0.005797101449275362, ('again', 'and', 'when'): 0.005797101449275362, ('and', 'when', 'they'): 0.005797101449275362, ('when', 'they', 'had'): 0.005797101449275362, ('they', 'had', 'performed'): 0.005797101449275362, ('had', 'performed', 'this'): 0.005797101449275362, ('performed', 'this', 'operation'): 0.005797101449275362, ('this', 'operation', 'which'): 0.005797101449275362, ('operation', 'which', 'never'): 0.005797101449275362, ('which', 'never', 'took'): 0.005797101449275362, ('never', 'took', 'very'): 0.005797101449275362, ('took', 'very', 'long'): 0.005797101449275362, ('very', 'long', 'the'): 0.005797101449275362, ('long', 'the', 'spoons'): 0.005797101449275362, ('the', 'spoons', 'being'): 0.005797101449275362, ('spoons', 'being', 'nearly'): 0.005797101449275362, ('being', 'nearly', 'as'): 0.005797101449275362, ('nearly', 'as', 'large'): 0.005797101449275362, ('as', 'large', 'as'): 0.005797101449275362, ('large', 'as', 'the'): 0.005797101449275362, ('as', 'the', 'bowls'): 0.005797101449275362, ('the', 'bowls', 'they'): 0.005780346820809248, ('bowls', 'they', 'would'): 0.005797101449275362, ('they', 'would', 'sit'): 0.005797101449275362, ('would', 'sit', 'staring'): 0.005797101449275362, ('sit', 'staring', 'at'): 0.005797101449275362, ('staring', 'at', 'the'): 0.005797101449275362, ('at', 'the', 'copper'): 0.008670520231213872, ('the', 'copper', 'with'): 0.005763688760806916, ('copper', 'with', 'such'): 0.005797101449275362, ('with', 'such', 'eager'): 0.005797101449275362, ('such', 'eager', 'eyes'): 0.005797101449275362, ('eager', 'eyes', 'as'): 0.005797101449275362, ('eyes', 'as', 'if'): 0.005797101449275362, ('as', 'if', 'they'): 0.005797101449275362, ('if', 'they', 'could'): 0.005797101449275362, ('they', 'could', 'have'): 0.005797101449275362, ('could', 'have', 'devoured'): 0.005797101449275362, ('have', 'devoured', 'the'): 0.005797101449275362, ('devoured', 'the', 'very'): 0.005797101449275362, ('the', 'very', 'bricks'): 0.005797101449275362, ('very', 'bricks', 'of'): 0.005797101449275362, ('bricks', 'of', 'which'): 0.005797101449275362, ('of', 'which', 'it'): 0.005780346820809248, ('which', 'it', 'was'): 0.005797101449275362, ('it', 'was', 'composed'): 0.005797101449275362, ('was', 'composed', 'employing'): 0.005797101449275362, ('composed', 'employing', 'themselves'): 0.005797101449275362, ('employing', 'themselves', 'meanwhile'): 0.005797101449275362, ('themselves', 'meanwhile', 'in'): 0.005797101449275362, ('meanwhile', 'in', 'sucking'): 0.005797101449275362, ('in', 'sucking', 'their'): 0.005797101449275362, ('sucking', 'their', 'fingers'): 0.005797101449275362, ('their', 'fingers', 'most'): 0.005797101449275362, ('fingers', 'most', 'assiduously'): 0.005797101449275362, ('most', 'assiduously', 'diligently'): 0.005797101449275362, ('assiduously', 'diligently', 'with'): 0.005797101449275362, ('diligently', 'with', 'the'): 0.005797101449275362, ('with', 'the', 'view'): 0.005763688760806916, ('the', 'view', 'of'): 0.005797101449275362, ('view', 'of', 'catching'): 0.005797101449275362, ('of', 'catching', 'up'): 0.005797101449275362, ('catching', 'up', 'any'): 0.005797101449275362, ('up', 'any', 'stray'): 0.005797101449275362, ('any', 'stray', 'splashes'): 0.005797101449275362, ('stray', 'splashes', 'of'): 0.005797101449275362, ('splashes', 'of', 'gruel'): 0.005797101449275362, ('of', 'gruel', 'that'): 0.005780346820809248, ('gruel', 'that', 'ight'): 0.005797101449275362, ('that', 'ight', 'have'): 0.005797101449275362, ('ight', 'have', 'been'): 0.005797101449275362, ('have', 'been', 'cast'): 0.005797101449275362, ('been', 'cast', 'thereon'): 0.005797101449275362, ('boys', 'have', 'generally'): 0.005797101449275362, ('have', 'generally', 'excellent'): 0.005797101449275362, ('generally', 'excellent', 'appetites'): 0.005797101449275362, ('oliver', 'twist', 'and'): 0.0057306590257879654, ('twist', 'and', 'his'): 0.005797101449275362, ('and', 'his', 'companions'): 0.005797101449275362, ('his', 'companions', 'suffered'): 0.005780346820809248, ('companions', 'suffered', 'the'): 0.005797101449275362, ('suffered', 'the', 'ortures'): 0.005797101449275362, ('the', 'ortures', 'of'): 0.005797101449275362, ('ortures', 'of', 'slow'): 0.005797101449275362, ('of', 'slow', 'starvation'): 0.005797101449275362, ('slow', 'starvation', 'for'): 0.005797101449275362, ('starvation', 'for', 'three'): 0.005797101449275362, ('for', 'three', 'months'): 0.005797101449275362, ('three', 'months', 'at'): 0.005797101449275362, ('months', 'at', 'last'): 0.005797101449275362, ('at', 'last', 'they'): 0.005797101449275362, ('last', 'they', 'got'): 0.005797101449275362, ('they', 'got', 'so'): 0.005797101449275362, ('got', 'so', 'voracious'): 0.005797101449275362, ('so', 'voracious', 'and'): 0.005797101449275362, ('voracious', 'and', 'wild'): 0.005797101449275362, ('and', 'wild', 'with'): 0.005797101449275362, ('wild', 'with', 'hunger'): 0.005797101449275362, ('with', 'hunger', 'that'): 0.005780346820809248, ('hunger', 'that', 'one'): 0.005797101449275362, ('that', 'one', 'boy'): 0.005797101449275362, ('one', 'boy', 'who'): 0.005797101449275362, ('boy', 'who', 'was'): 0.005780346820809248, ('who', 'was', 'tall'): 0.005797101449275362, ('was', 'tall', 'for'): 0.005797101449275362, ('tall', 'for', 'his'): 0.005797101449275362, ('for', 'his', 'age'): 0.005780346820809248, ('his', 'age', 'and'): 0.005797101449275362, ('age', 'and', 'hadnt'): 0.005797101449275362, ('and', 'hadnt', 'been'): 0.005797101449275362, ('hadnt', 'been', 'used'): 0.005797101449275362, ('been', 'used', 'to'): 0.005797101449275362, ('used', 'to', 'that'): 0.005797101449275362, ('to', 'that', 'sort'): 0.005797101449275362, ('that', 'sort', 'of'): 0.005797101449275362, ('sort', 'of', 'thing'): 0.005797101449275362, ('of', 'thing', 'for'): 0.005797101449275362, ('thing', 'for', 'his'): 0.005797101449275362, ('for', 'his', 'father'): 0.005780346820809248, ('his', 'father', 'had'): 0.005797101449275362, ('father', 'had', 'kept'): 0.005797101449275362, ('had', 'kept', 'a'): 0.005797101449275362, ('kept', 'a', 'small'): 0.005797101449275362, ('a', 'small', 'cookshop'): 0.005797101449275362, ('small', 'cookshop', 'hinted'): 0.005797101449275362, ('cookshop', 'hinted', 'darkly'): 0.005797101449275362, ('hinted', 'darkly', 'to'): 0.005797101449275362, ('darkly', 'to', 'his'): 0.005797101449275362, ('to', 'his', 'companions'): 0.005797101449275362, ('his', 'companions', 'that'): 0.005780346820809248, ('companions', 'that', 'unless'): 0.005797101449275362, ('that', 'unless', 'he'): 0.005797101449275362, ('unless', 'he', 'had'): 0.005797101449275362, ('he', 'had', 'another'): 0.005747126436781609, ('had', 'another', 'basin'): 0.005797101449275362, ('another', 'basin', 'of'): 0.005797101449275362, ('basin', 'of', 'gruel'): 0.005797101449275362, ('of', 'gruel', 'per'): 0.005780346820809248, ('gruel', 'per', 'diem'): 0.005797101449275362, ('per', 'diem', 'each'): 0.005797101449275362, ('diem', 'each', 'day'): 0.005797101449275362, ('each', 'day', 'he'): 0.005797101449275362, ('day', 'he', 'was'): 0.005797101449275362, ('he', 'was', 'afraid'): 0.005763688760806916, ('was', 'afraid', 'he'): 0.005797101449275362, ('afraid', 'he', 'might'): 0.005797101449275362, ('he', 'might', 'some'): 0.005797101449275362, ('might', 'some', 'night'): 0.005797101449275362, ('some', 'night', 'happen'): 0.005797101449275362, ('night', 'happen', 'to'): 0.005797101449275362, ('happen', 'to', 'eat'): 0.005797101449275362, ('to', 'eat', 'the'): 0.005797101449275362, ('eat', 'the', 'boy'): 0.005797101449275362, ('the', 'boy', 'who'): 0.005797101449275362, ('boy', 'who', 'slept'): 0.005780346820809248, ('who', 'slept', 'next'): 0.005797101449275362, ('slept', 'next', 'him'): 0.005797101449275362, ('next', 'him', 'who'): 0.005797101449275362, ('him', 'who', 'happened'): 0.005797101449275362, ('who', 'happened', 'to'): 0.005797101449275362, ('happened', 'to', 'be'): 0.005797101449275362, ('to', 'be', 'a'): 0.005797101449275362, ('be', 'a', 'weakly'): 0.005797101449275362, ('a', 'weakly', 'youth'): 0.005797101449275362, ('weakly', 'youth', 'of'): 0.005797101449275362, ('youth', 'of', 'tender'): 0.005797101449275362, ('of', 'tender', 'age'): 0.005797101449275362, ('he', 'had', 'a'): 0.005747126436781609, ('had', 'a', 'wild'): 0.005797101449275362, ('a', 'wild', 'hungry'): 0.005797101449275362, ('wild', 'hungry', 'eye'): 0.005797101449275362, ('hungry', 'eye', 'and'): 0.005797101449275362, ('eye', 'and', 'they'): 0.005797101449275362, ('and', 'they', 'implicitly'): 0.005797101449275362, ('they', 'implicitly', 'believed'): 0.005797101449275362, ('implicitly', 'believed', 'him'): 0.005797101449275362, ('a', 'council', 'was'): 0.005797101449275362, ('council', 'was', 'held'): 0.005797101449275362, ('was', 'held', 'lots'): 0.005797101449275362, ('held', 'lots', 'objects'): 0.005797101449275362, ('lots', 'objects', 'such'): 0.005797101449275362, ('objects', 'such', 'as'): 0.005797101449275362, ('such', 'as', 'straws'): 0.005797101449275362, ('as', 'straws', 'that'): 0.005797101449275362, ('straws', 'that', 'would'): 0.005797101449275362, ('that', 'would', 'be'): 0.005797101449275362, ('would', 'be', 'taken'): 0.005797101449275362, ('be', 'taken', 'out'): 0.005797101449275362, ('taken', 'out', 'of'): 0.005797101449275362, ('out', 'of', 'a'): 0.005780346820809248, ('of', 'a', 'container'): 0.005797101449275362, ('a', 'container', 'to'): 0.005797101449275362, ('container', 'to', 'make'): 0.005797101449275362, ('to', 'make', 'a'): 0.005797101449275362, ('make', 'a', 'decision'): 0.005797101449275362, ('a', 'decision', 'or'): 0.005797101449275362, ('decision', 'or', 'choice'): 0.005797101449275362, ('or', 'choice', 'were'): 0.005797101449275362, ('choice', 'were', 'cast'): 0.005797101449275362, ('were', 'cast', 'who'): 0.005797101449275362, ('cast', 'who', 'should'): 0.005797101449275362, ('who', 'should', 'walk'): 0.005797101449275362, ('should', 'walk', 'up'): 0.005797101449275362, ('walk', 'up', 'to'): 0.005797101449275362, ('up', 'to', 'the'): 0.005797101449275362, ('to', 'the', 'master'): 0.008645533141210375, ('the', 'master', 'after'): 0.005698005698005698, ('master', 'after', 'supper'): 0.005797101449275362, ('after', 'supper', 'that'): 0.005797101449275362, ('supper', 'that', 'evening'): 0.005797101449275362, ('that', 'evening', 'and'): 0.005797101449275362, ('evening', 'and', 'ask'): 0.005797101449275362, ('and', 'ask', 'for'): 0.005797101449275362, ('ask', 'for', 'more'): 0.005797101449275362, ('for', 'more', 'and'): 0.005747126436781609, ('more', 'and', 'it'): 0.005797101449275362, ('and', 'it', 'fell'): 0.005797101449275362, ('it', 'fell', 'to'): 0.005797101449275362, ('fell', 'to', 'oliver'): 0.005797101449275362, ('to', 'oliver', 'twist'): 0.005797101449275362, ('the', 'evening', 'arrived'): 0.005797101449275362, ('evening', 'arrived', 'the'): 0.005797101449275362, ('arrived', 'the', 'boys'): 0.005797101449275362, ('the', 'boys', 'took'): 0.0057306590257879654, ('boys', 'took', 'their'): 0.005797101449275362, ('took', 'their', 'places'): 0.005797101449275362, ('the', 'master', 'in'): 0.005698005698005698, ('master', 'in', 'his'): 0.005797101449275362, ('in', 'his', 'cooks'): 0.005780346820809248, ('his', 'cooks', 'uniform'): 0.005797101449275362, ('cooks', 'uniform', 'stationed'): 0.005797101449275362, ('uniform', 'stationed', 'himself'): 0.005797101449275362, ('stationed', 'himself', 'at'): 0.005797101449275362, ('himself', 'at', 'the'): 0.005797101449275362, ('the', 'copper', 'his'): 0.005763688760806916, ('copper', 'his', 'pauper'): 0.005797101449275362, ('his', 'pauper', 'poor'): 0.005797101449275362, ('pauper', 'poor', 'assistants'): 0.005797101449275362, ('poor', 'assistants', 'ranged'): 0.005797101449275362, ('assistants', 'ranged', 'themselves'): 0.005797101449275362, ('ranged', 'themselves', 'behind'): 0.005797101449275362, ('themselves', 'behind', 'him'): 0.005797101449275362, ('behind', 'him', 'the'): 0.005797101449275362, ('him', 'the', 'gruel'): 0.005797101449275362, ('the', 'gruel', 'was'): 0.005763688760806916, ('gruel', 'was', 'served'): 0.005797101449275362, ('was', 'served', 'out'): 0.005797101449275362, ('served', 'out', 'and'): 0.005797101449275362, ('out', 'and', 'a'): 0.005797101449275362, ('and', 'a', 'long'): 0.005763688760806916, ('a', 'long', 'grace'): 0.005797101449275362, ('long', 'grace', 'was'): 0.005797101449275362, ('grace', 'was', 'said'): 0.005797101449275362, ('was', 'said', 'over'): 0.005797101449275362, ('said', 'over', 'the'): 0.005797101449275362, ('over', 'the', 'short'): 0.005797101449275362, ('the', 'short', 'commons'): 0.005797101449275362, ('the', 'gruel', 'disappeared'): 0.005763688760806916, ('gruel', 'disappeared', 'the'): 0.005797101449275362, ('disappeared', 'the', 'boys'): 0.005797101449275362, ('the', 'boys', 'whispered'): 0.0057306590257879654, ('boys', 'whispered', 'each'): 0.005797101449275362, ('whispered', 'each', 'other'): 0.005797101449275362, ('each', 'other', 'and'): 0.005797101449275362, ('other', 'and', 'winked'): 0.005797101449275362, ('and', 'winked', 'at'): 0.005797101449275362, ('winked', 'at', 'oliver'): 0.005797101449275362, ('at', 'oliver', 'while'): 0.005797101449275362, ('oliver', 'while', 'his'): 0.005797101449275362, ('while', 'his', 'next'): 0.005797101449275362, ('his', 'next', 'neighbors'): 0.005797101449275362, ('next', 'neighbors', 'nudged'): 0.005797101449275362, ('neighbors', 'nudged', 'him'): 0.005797101449275362, ('child', 'as', 'he'): 0.005797101449275362, ('as', 'he', 'was'): 0.005797101449275362, ('he', 'was', 'he'): 0.005763688760806916, ('was', 'he', 'was'): 0.005797101449275362, ('he', 'was', 'desperate'): 0.005763688760806916, ('was', 'desperate', 'with'): 0.005797101449275362, ('desperate', 'with', 'hunger'): 0.005797101449275362, ('with', 'hunger', 'and'): 0.005780346820809248, ('hunger', 'and', 'reckless'): 0.005797101449275362, ('and', 'reckless', 'with'): 0.005797101449275362, ('reckless', 'with', 'misery'): 0.005797101449275362, ('he', 'rose', 'from'): 0.005797101449275362, ('rose', 'from', 'the'): 0.005797101449275362, ('from', 'the', 'table'): 0.005797101449275362, ('the', 'table', 'and'): 0.005797101449275362, ('table', 'and', 'advancing'): 0.005797101449275362, ('and', 'advancing', 'to'): 0.005797101449275362, ('advancing', 'to', 'the'): 0.005797101449275362, ('the', 'master', 'basin'): 0.005698005698005698, ('master', 'basin', 'and'): 0.005797101449275362, ('basin', 'and', 'spoon'): 0.005797101449275362, ('and', 'spoon', 'in'): 0.005797101449275362, ('spoon', 'in', 'hand'): 0.005797101449275362, ('in', 'hand', 'said'): 0.005797101449275362, ('hand', 'said', 'somewhat'): 0.005797101449275362, ('said', 'somewhat', 'alarmed'): 0.005797101449275362, ('somewhat', 'alarmed', 'at'): 0.005797101449275362, ('alarmed', 'at', 'his'): 0.005797101449275362, ('at', 'his', 'own'): 0.005797101449275362, ('his', 'own', 'temerity'): 0.005797101449275362, ('own', 'temerity', 'bravery'): 0.005797101449275362, ('temerity', 'bravery', 'please'): 0.005797101449275362, ('bravery', 'please', 'sir'): 0.005797101449275362, ('please', 'sir', 'i'): 0.005780346820809248, ('sir', 'i', 'want'): 0.005797101449275362, ('i', 'want', 'some'): 0.008670520231213872, ('want', 'some', 'more'): 0.008670520231213872, ('the', 'master', 'was'): 0.005698005698005698, ('master', 'was', 'a'): 0.005797101449275362, ('was', 'a', 'fat'): 0.005763688760806916, ('a', 'fat', 'healthy'): 0.005797101449275362, ('fat', 'healthy', 'man'): 0.005797101449275362, ('healthy', 'man', 'but'): 0.005797101449275362, ('man', 'but', 'he'): 0.005797101449275362, ('but', 'he', 'turned'): 0.005797101449275362, ('he', 'turned', 'very'): 0.005797101449275362, ('turned', 'very', 'pale'): 0.005797101449275362, ('he', 'gazed', 'in'): 0.005797101449275362, ('gazed', 'in', 'stupefied'): 0.005797101449275362, ('in', 'stupefied', 'astonishment'): 0.005797101449275362, ('stupefied', 'astonishment', 'on'): 0.005797101449275362, ('astonishment', 'on', 'the'): 0.005797101449275362, ('on', 'the', 'small'): 0.005780346820809248, ('the', 'small', 'rebel'): 0.005797101449275362, ('small', 'rebel', 'for'): 0.005797101449275362, ('rebel', 'for', 'some'): 0.005797101449275362, ('for', 'some', 'seconds'): 0.005797101449275362, ('some', 'seconds', 'and'): 0.005797101449275362, ('seconds', 'and', 'then'): 0.005797101449275362, ('and', 'then', 'clung'): 0.005797101449275362, ('then', 'clung', 'for'): 0.005797101449275362, ('clung', 'for', 'support'): 0.005797101449275362, ('for', 'support', 'to'): 0.005797101449275362, ('support', 'to', 'the'): 0.005797101449275362, ('to', 'the', 'copper'): 0.005763688760806916, ('the', 'assistants', 'were'): 0.005797101449275362, ('assistants', 'were', 'paralysed'): 0.005797101449275362, ('were', 'paralysed', 'with'): 0.005797101449275362, ('paralysed', 'with', 'wonder'): 0.005797101449275362, ('with', 'wonder', 'the'): 0.005797101449275362, ('wonder', 'the', 'boys'): 0.005797101449275362, ('the', 'boys', 'with'): 0.0057306590257879654, ('boys', 'with', 'fear'): 0.005797101449275362, ('what', 'said', 'the'): 0.005797101449275362, ('said', 'the', 'master'): 0.005780346820809248, ('the', 'master', 'at'): 0.005698005698005698, ('master', 'at', 'length'): 0.005797101449275362, ('at', 'length', 'in'): 0.005797101449275362, ('length', 'in', 'a'): 0.005797101449275362, ('in', 'a', 'faint'): 0.005797101449275362, ('a', 'faint', 'voice'): 0.005797101449275362, ('please', 'sir', 'replied'): 0.005780346820809248, ('sir', 'replied', 'oliver'): 0.005780346820809248, ('replied', 'oliver', 'i'): 0.005797101449275362, ('oliver', 'i', 'want'): 0.005797101449275362, ('the', 'master', 'aimed'): 0.005698005698005698, ('master', 'aimed', 'a'): 0.005797101449275362, ('aimed', 'a', 'blow'): 0.005797101449275362, ('a', 'blow', 'at'): 0.005797101449275362, ('blow', 'at', 'olivers'): 0.005797101449275362, ('at', 'olivers', 'head'): 0.005797101449275362, ('olivers', 'head', 'with'): 0.005797101449275362, ('head', 'with', 'the'): 0.005797101449275362, ('with', 'the', 'ladle'): 0.005763688760806916, ('the', 'ladle', 'pinioned'): 0.005797101449275362, ('ladle', 'pinioned', 'trapped'): 0.005797101449275362, ('pinioned', 'trapped', 'him'): 0.005797101449275362, ('trapped', 'him', 'in'): 0.005797101449275362, ('him', 'in', 'his'): 0.005797101449275362, ('in', 'his', 'arm'): 0.005780346820809248, ('his', 'arm', 'and'): 0.005797101449275362, ('arm', 'and', 'shrieked'): 0.005797101449275362, ('and', 'shrieked', 'aloud'): 0.005797101449275362, ('shrieked', 'aloud', 'for'): 0.005797101449275362, ('aloud', 'for', 'the'): 0.005797101449275362, ('for', 'the', 'beadle'): 0.005780346820809248, ('the', 'beadle', 'an'): 0.005797101449275362, ('beadle', 'an', 'official'): 0.005797101449275362, ('the', 'board', 'were'): 0.005797101449275362, ('board', 'were', 'sitting'): 0.005797101449275362, ('were', 'sitting', 'in'): 0.005797101449275362, ('sitting', 'in', 'solemn'): 0.005797101449275362, ('in', 'solemn', 'conclave'): 0.005797101449275362, ('solemn', 'conclave', 'meeting'): 0.005797101449275362, ('conclave', 'meeting', 'when'): 0.005797101449275362, ('meeting', 'when', 'mr.'): 0.005797101449275362, ('when', 'mr.', 'bumble'): 0.005797101449275362, ('mr.', 'bumble', 'rushed'): 0.005797101449275362, ('bumble', 'rushed', 'into'): 0.005797101449275362, ('rushed', 'into', 'the'): 0.005797101449275362, ('into', 'the', 'room'): 0.005797101449275362, ('room', 'in', 'great'): 0.005780346820809248, ('in', 'great', 'excitement'): 0.005797101449275362, ('great', 'excitement', 'and'): 0.005797101449275362, ('excitement', 'and', 'addressing'): 0.005797101449275362, ('and', 'addressing', 'the'): 0.005797101449275362, ('addressing', 'the', 'gentleman'): 0.005797101449275362, ('the', 'gentleman', 'in'): 0.008670520231213872, ('gentleman', 'in', 'the'): 0.008670520231213872, ('in', 'the', 'high'): 0.005780346820809248, ('the', 'high', 'chair'): 0.005797101449275362, ('high', 'chair', 'said'): 0.005797101449275362, ('chair', 'said', 'mr.'): 0.005797101449275362, ('said', 'mr.', 'limbkins'): 0.008670520231213872, ('mr.', 'limbkins', 'i'): 0.005780346820809248, ('limbkins', 'i', 'beg'): 0.005797101449275362, ('i', 'beg', 'your'): 0.005797101449275362, ('beg', 'your', 'pardon'): 0.005797101449275362, ('your', 'pardon', 'sir'): 0.005797101449275362, ('pardon', 'sir', 'oliver'): 0.005797101449275362, ('sir', 'oliver', 'twist'): 0.005797101449275362, ('oliver', 'twist', 'has'): 0.0057306590257879654, ('twist', 'has', 'asked'): 0.005797101449275362, ('has', 'asked', 'for'): 0.005797101449275362, ('asked', 'for', 'more'): 0.008670520231213872, ('for', 'more', 'there'): 0.005747126436781609, ('more', 'there', 'was'): 0.005797101449275362, ('there', 'was', 'a'): 0.005797101449275362, ('was', 'a', 'general'): 0.005763688760806916, ('a', 'general', 'start'): 0.005797101449275362, ('horror', 'was', 'depicted'): 0.005797101449275362, ('was', 'depicted', 'on'): 0.005797101449275362, ('depicted', 'on', 'every'): 0.005797101449275362, ('on', 'every', 'countenance'): 0.005797101449275362, ('every', 'countenance', 'face'): 0.005797101449275362, ('for', 'more', 'said'): 0.005747126436781609, ('more', 'said', 'mr.'): 0.005797101449275362, ('compose', 'yourself', 'bumble'): 0.005797101449275362, ('yourself', 'bumble', 'and'): 0.005797101449275362, ('bumble', 'and', 'answer'): 0.005797101449275362, ('and', 'answer', 'me'): 0.005797101449275362, ('answer', 'me', 'distinctly'): 0.005797101449275362, ('me', 'distinctly', 'clearly'): 0.005797101449275362, ('do', 'i', 'understand'): 0.005797101449275362, ('i', 'understand', 'that'): 0.005797101449275362, ('understand', 'that', 'he'): 0.005797101449275362, ('that', 'he', 'asked'): 0.005797101449275362, ('he', 'asked', 'for'): 0.005797101449275362, ('for', 'more', 'after'): 0.005747126436781609, ('more', 'after', 'he'): 0.005797101449275362, ('after', 'he', 'had'): 0.005797101449275362, ('he', 'had', 'eaten'): 0.005747126436781609, ('had', 'eaten', 'the'): 0.005797101449275362, ('eaten', 'the', 'supper'): 0.005797101449275362, ('the', 'supper', 'allotted'): 0.005797101449275362, ('supper', 'allotted', 'by'): 0.005797101449275362, ('allotted', 'by', 'the'): 0.005797101449275362, ('by', 'the', 'dietary'): 0.005797101449275362, ('the', 'dietary', 'he'): 0.005797101449275362, ('dietary', 'he', 'did'): 0.005797101449275362, ('he', 'did', 'sir'): 0.005797101449275362, ('did', 'sir', 'replied'): 0.005797101449275362, ('sir', 'replied', 'bumble'): 0.005780346820809248, ('that', 'boy', 'will'): 0.008670520231213872, ('boy', 'will', 'be'): 0.008670520231213872, ('will', 'be', 'hung'): 0.008670520231213872, ('be', 'hung', 'said'): 0.005780346820809248, ('hung', 'said', 'the'): 0.005797101449275362, ('said', 'the', 'gentleman'): 0.005780346820809248, ('in', 'the', 'white'): 0.005780346820809248, ('the', 'white', 'waistcoat'): 0.005797101449275362, ('i', 'know', 'that'): 0.005797101449275362, ('know', 'that', 'boy'): 0.005797101449275362, ('nobody', 'controverted', 'argued'): 0.005797101449275362, ('controverted', 'argued', 'with'): 0.005797101449275362, ('argued', 'with', 'the'): 0.005797101449275362, ('with', 'the', 'prophetic'): 0.005763688760806916, ('the', 'prophetic', 'gentlemans'): 0.005797101449275362, ('prophetic', 'gentlemans', 'opinion'): 0.005797101449275362, ('an', 'animated', 'discussion'): 0.005797101449275362, ('animated', 'discussion', 'took'): 0.005797101449275362, ('discussion', 'took', 'place'): 0.005797101449275362, ('oliver', 'was', 'ordered'): 0.005797101449275362, ('was', 'ordered', 'into'): 0.005797101449275362, ('ordered', 'into', 'instant'): 0.005797101449275362, ('into', 'instant', 'confinement'): 0.005797101449275362, ('instant', 'confinement', 'and'): 0.005797101449275362, ('confinement', 'and', 'a'): 0.005797101449275362, ('and', 'a', 'bill'): 0.005763688760806916, ('a', 'bill', 'was'): 0.005797101449275362, ('bill', 'was', 'next'): 0.005797101449275362, ('was', 'next', 'morning'): 0.005797101449275362, ('next', 'morning', 'pasted'): 0.005797101449275362, ('morning', 'pasted', 'on'): 0.005797101449275362, ('pasted', 'on', 'the'): 0.005797101449275362, ('on', 'the', 'outside'): 0.005780346820809248, ('the', 'outside', 'of'): 0.005797101449275362, ('outside', 'of', 'the'): 0.005797101449275362, ('of', 'the', 'gate'): 0.005780346820809248, ('the', 'gate', 'offering'): 0.005797101449275362, ('gate', 'offering', 'a'): 0.005797101449275362, ('offering', 'a', 'reward'): 0.005797101449275362, ('a', 'reward', 'of'): 0.005797101449275362, ('reward', 'of', 'five'): 0.005797101449275362, ('of', 'five', 'pounds'): 0.005797101449275362, ('five', 'pounds', 'to'): 0.005780346820809248, ('pounds', 'to', 'anybody'): 0.005797101449275362, ('to', 'anybody', 'who'): 0.005797101449275362, ('anybody', 'who', 'would'): 0.005797101449275362, ('who', 'would', 'take'): 0.005797101449275362, ('would', 'take', 'oliver'): 0.005797101449275362, ('take', 'oliver', 'twist'): 0.005797101449275362, ('oliver', 'twist', 'off'): 0.0057306590257879654, ('twist', 'off', 'the'): 0.005797101449275362, ('off', 'the', 'hands'): 0.005797101449275362, ('the', 'hands', 'of'): 0.005797101449275362, ('hands', 'of', 'the'): 0.005797101449275362, ('of', 'the', 'parish'): 0.005780346820809248, ('in', 'other', 'words'): 0.005797101449275362, ('other', 'words', 'five'): 0.005797101449275362, ('words', 'five', 'pounds'): 0.005797101449275362, ('five', 'pounds', 'and'): 0.005780346820809248, ('pounds', 'and', 'oliver'): 0.005797101449275362, ('and', 'oliver', 'twist'): 0.005797101449275362, ('oliver', 'twist', 'were'): 0.0057306590257879654, ('twist', 'were', 'offered'): 0.005797101449275362, ('were', 'offered', 'to'): 0.005797101449275362, ('offered', 'to', 'any'): 0.005797101449275362, ('to', 'any', 'man'): 0.005780346820809248, ('any', 'man', 'or'): 0.005797101449275362, ('man', 'or', 'woman'): 0.005797101449275362, ('or', 'woman', 'who'): 0.005797101449275362, ('woman', 'who', 'wanted'): 0.005797101449275362, ('who', 'wanted', 'an'): 0.005797101449275362, ('wanted', 'an', 'apprentice'): 0.005797101449275362, ('an', 'apprentice', 'to'): 0.005797101449275362, ('apprentice', 'to', 'any'): 0.005797101449275362, ('to', 'any', 'trade'): 0.005780346820809248, ('any', 'trade', 'business'): 0.005797101449275362, ('trade', 'business', 'or'): 0.005797101449275362, ('business', 'or', 'calling'): 0.005797101449275362}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "testSent1 = \"The assistants were paralysed with wonder; the boys\"\n",
        "testSent2 = \"Do I understand that he asked for more, after he had\"\n",
        "testSent3 = \"The room in which the boys were fed, was a large stone hall, with a\""
      ],
      "metadata": {
        "id": "NUdU1Oo0_Qcw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "token_1 = word_tokenize(testSent1)\n",
        "token_2 = word_tokenize(testSent2)\n",
        "token_3 = word_tokenize(testSent3)\n",
        "ngram_1 = {1:[], 2:[]}\n",
        "ngram_2 = {1:[], 2:[]}\n",
        "ngram_3 = {1:[], 2:[]}\n",
        "for i in range(2):\n",
        "    ngram_1[i+1] = list(ngrams(token_1, i+1))[-1]\n",
        "    ngram_2[i+1] = list(ngrams(token_2, i+1))[-1]\n",
        "    ngram_3[i+1] = list(ngrams(token_3, i+1))[-1]\n",
        "print(\"Sentence 1: \", ngram_1,\"\\nSentence 2: \",ngram_2,\"\\nSentence 3: \",ngram_3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kXev5O3rG4Oy",
        "outputId": "bdb5581d-9ccb-4611-9150-6243b5ce57ea"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sentence 1:  {1: ('boys',), 2: ('the', 'boys')} \n",
            "Sentence 2:  {1: ('had',), 2: ('he', 'had')} \n",
            "Sentence 3:  {1: ('a',), 2: ('with', 'a')}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_next_word(last_word,probDist):\n",
        "    next_word = {}\n",
        "    for k in probDist:\n",
        "        if k[0] == last_word[0]:\n",
        "            next_word[k[1]] = probDist[k]\n",
        "    k = Counter(next_word)\n",
        "    high = k.most_common(1)\n",
        "    return high[0]\n",
        "def predict_next_3_words(token,probDist):\n",
        "    pred1 = []\n",
        "    pred2 = []\n",
        "    next_word = {}\n",
        "    for i in probDist:\n",
        "        if i[0] == token:\n",
        "            next_word[i[1]] = probDist[i]\n",
        "    k = Counter(next_word)\n",
        "    high = k.most_common(2)\n",
        "    w1a = high[0]\n",
        "    w1b = high[1]\n",
        "    w2a = predict_next_word(w1a,probDist)\n",
        "    w3a = predict_next_word(w2a,probDist)\n",
        "    w2b = predict_next_word(w1b,probDist)\n",
        "    w3b = predict_next_word(w2b,probDist)\n",
        "    pred1.append(w1a)\n",
        "    pred1.append(w2a)\n",
        "    pred1.append(w3a)\n",
        "    pred2.append(w1b)\n",
        "    pred2.append(w2b)\n",
        "    pred2.append(w3b)\n",
        "    return pred1,pred2\n",
        "print(\"Predicting next 3 possible word sequences with smoothed bigram model : \")\n",
        "pred1,pred2 = predict_next_3_words(ngram_1[1][0],smoothed_bigrams_probDist)\n",
        "print(\"1a)\" +testSent1 +\" \" + pred1[0][0]+\" \"+pred1[1][0]+\" \"+pred1[2][0])\n",
        "print(\"1b)\" +testSent1 +\" \" + pred2[0][0]+\" \"+pred2[1][0]+\" \"+pred2[2][0])\n",
        "pred1,pred2 = predict_next_3_words(ngram_2[1][0],smoothed_bigrams_probDist)\n",
        "print(\"2a)\" +testSent2 +\" \" + pred1[0][0]+\" \"+pred1[1][0]+\" \"+pred1[2][0])\n",
        "print(\"2b)\" +testSent2 +\" \" + pred2[0][0]+\" \"+pred2[1][0]+\" \"+pred2[2][0])\n",
        "pred1,pred2 = predict_next_3_words(ngram_3[1][0],smoothed_bigrams_probDist)\n",
        "print(\"3a)\" +testSent3 +\" \" + pred1[0][0]+\" \"+pred1[1][0]+\" \"+pred1[2][0])\n",
        "print(\"3b)\" +testSent3 +\" \" + pred2[0][0]+\" \"+pred2[1][0]+\" \"+pred2[2][0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t_f6kABjIQj6",
        "outputId": "3a3b5c93-8db6-4f4e-bb73-18222f282d55"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicting next 3 possible word sequences with smoothed bigram model : \n",
            "1a)The assistants were paralysed with wonder; the boys were fed was\n",
            "1b)The assistants were paralysed with wonder; the boys polished them with\n",
            "2a)Do I understand that he asked for more, after he had one end out\n",
            "2b)Do I understand that he asked for more, after he had two women ladled\n",
            "3a)The room in which the boys were fed, was a large stone hall, with a large stone hall\n",
            "3b)The room in which the boys were fed, was a large stone hall, with a copper a large\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_next_word(last_word,probDist):\n",
        "    next_word = {}\n",
        "    for k in probDist:\n",
        "        if k[0:2] == last_word:\n",
        "            next_word[k[2]] = probDist[k]\n",
        "    k = Counter(next_word)\n",
        "    high = k.most_common(1)\n",
        "    return high[0]\n",
        "def predict_next_3_words(token,probDist):\n",
        "    pred = []\n",
        "    next_word = {}\n",
        "    for i in probDist:\n",
        "        if i[0:2] == token:\n",
        "            next_word[i[2]] = probDist[i]\n",
        "    k = Counter(next_word)\n",
        "    high = k.most_common(2)\n",
        "    w1a = high[0]\n",
        "    tup = (token[1],w1a[0])\n",
        "    w2a = predict_next_word(tup,probDist)\n",
        "    tup = (w1a[0],w2a[0])\n",
        "    w3a = predict_next_word(tup,probDist)\n",
        "    pred.append(w1a)\n",
        "    pred.append(w2a)\n",
        "    pred.append(w3a)\n",
        "    return pred\n",
        "print(\"Predicting next 3 possible word sequences with smoothed trigram model : \")\n",
        "pred = predict_next_3_words(ngram_1[2],smoothed_trigrams_probDist)\n",
        "print(\"1)\" +testSent1 +\" \"+ pred[0][0]+\" \"+pred[1][0]+\" \"+pred[2][0])\n",
        "pred = predict_next_3_words(ngram_2[2],smoothed_trigrams_probDist)\n",
        "print(\"2)\" +testSent2 +\" \"+ pred[0][0]+\" \"+pred[1][0]+\" \"+pred[2][0])\n",
        "pred = predict_next_3_words(ngram_3[2],smoothed_trigrams_probDist)\n",
        "print(\"3)\" +testSent3 +\" \"+ pred[0][0]+\" \"+pred[1][0]+\" \"+pred[2][0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BAsMGvVXLYOi",
        "outputId": "6f6a6f7d-f218-432f-e0eb-6e6985511fe0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicting next 3 possible word sequences with smoothed trigram model : \n",
            "1)The assistants were paralysed with wonder; the boys were fed was\n",
            "2)Do I understand that he asked for more, after he had two ounces and\n",
            "3)The room in which the boys were fed, was a large stone hall, with a copper a large\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install langchain"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ejXiIQZcZnZ0",
        "outputId": "9899ca0d-001c-4eea-92e5-94fbcc1665a3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: langchain in /usr/local/lib/python3.10/dist-packages (0.2.6)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (6.0.1)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.0.31)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (3.9.5)\n",
            "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (4.0.3)\n",
            "Requirement already satisfied: langchain-core<0.3.0,>=0.2.10 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.2.10)\n",
            "Requirement already satisfied: langchain-text-splitters<0.3.0,>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.2.2)\n",
            "Requirement already satisfied: langsmith<0.2.0,>=0.1.17 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.1.82)\n",
            "Requirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.25.2)\n",
            "Requirement already satisfied: pydantic<3,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.7.4)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.31.0)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (8.4.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.9.4)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3.0,>=0.2.10->langchain) (1.33)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3.0,>=0.2.10->langchain) (24.1)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.17->langchain) (3.10.5)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.18.4 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain) (2.18.4)\n",
            "Requirement already satisfied: typing-extensions>=4.6.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2024.6.2)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.0.3)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.3.0,>=0.2.10->langchain) (3.0.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text=\"The room in which the boys were fed, was a large stone hall, with a copper [a large, heated copper pot] at one end: out of which the master, dressed in an apron for the purpose, and assisted by one or two women, ladled the gruel [a watery cereal like very thin oatmeal] at mealtimes. Of this festive composition each boy had one porringer [small bowl], and no more—except on occasions of great public rejoicing, when he had two ounces and a quarter of bread besides. The bowls never wanted washing. The boys polished them with their spoons till they shone again; and when they had performed this operation (which never took very long, the spoons being nearly as large as the bowls), they would sit staring at the copper, with such eager eyes, as if they could have devoured the very bricks of which it was composed; employing themselves, meanwhile, in sucking their fingers most assiduously [diligently], with the view of catching up any stray splashes of gruel that  ight have been cast thereon. Boys have generally excellent appetites. Oliver Twist and his companions suffered the  ortures of slow starvation for three months: at last they got so voracious and wild with hunger, that one boy, who was tall for his age, and hadn’t been used to that sort of thing (for his father had kept a small cook-shop), hinted darkly to his companions, that unless he had another basin of gruel per diem [each day], he was afraid he might some night happen to eat the boy who slept next him, who happened to be a weakly youth of tender age. He had a wild, hungry eye; and they implicitly believed him. A council was held; lots [objects, such as straws, that would be taken out of a container to make a decision or choice] were cast who should walk up to the master after supper that evening, and ask for more; and it fell to Oliver Twist.\"\n",
        "from langchain.text_splitter import CharacterTextSplitter\n",
        "text_splitter = CharacterTextSplitter(separator = \"\\n\\n\",chunk_size = 256,chunk_overlap  = 20)\n",
        "docs = text_splitter.create_documents([text])"
      ],
      "metadata": {
        "id": "u2lQ1DRPY0G1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(docs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bOiWkPWvZSM7",
        "outputId": "49897117-de1f-406c-fa74-de594cd9663c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Document(page_content='The room in which the boys were fed, was a large stone hall, with a copper [a large, heated copper pot] at one end: out of which the master, dressed in an apron for the purpose, and assisted by one or two women, ladled the gruel [a watery cereal like very thin oatmeal] at mealtimes. Of this festive composition each boy had one porringer [small bowl], and no more—except on occasions of great public rejoicing, when he had two ounces and a quarter of bread besides. The bowls never wanted washing. The boys polished them with their spoons till they shone again; and when they had performed this operation (which never took very long, the spoons being nearly as large as the bowls), they would sit staring at the copper, with such eager eyes, as if they could have devoured the very bricks of which it was composed; employing themselves, meanwhile, in sucking their fingers most assiduously [diligently], with the view of catching up any stray splashes of gruel that  ight have been cast thereon. Boys have generally excellent appetites. Oliver Twist and his companions suffered the  ortures of slow starvation for three months: at last they got so voracious and wild with hunger, that one boy, who was tall for his age, and hadn’t been used to that sort of thing (for his father had kept a small cook-shop), hinted darkly to his companions, that unless he had another basin of gruel per diem [each day], he was afraid he might some night happen to eat the boy who slept next him, who happened to be a weakly youth of tender age. He had a wild, hungry eye; and they implicitly believed him. A council was held; lots [objects, such as straws, that would be taken out of a container to make a decision or choice] were cast who should walk up to the master after supper that evening, and ask for more; and it fell to Oliver Twist.')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"The room in which the boys were fed, was a large stone hall, with a copper [a large, heated copper pot] at one end: out of which the master, dressed in an apron for the purpose, and assisted by one or two women, ladled the gruel [a watery cereal like very thin oatmeal] at mealtimes. Of this festive composition each boy had one porringer [small bowl], and no more—except on occasions of great public rejoicing, when he had two ounces and a quarter of bread besides. The bowls never wanted washing. The boys polished them with their spoons till they shone again; and when they had performed this operation (which never took very long, the spoons being nearly as large as the bowls), they would sit staring at the copper, with such eager eyes, as if they could have devoured the very bricks of which it was composed; employing themselves, meanwhile, in sucking their fingers most assiduously [diligently], with the view of catching up any stray splashes of gruel that  ight have been cast thereon. Boys have generally excellent appetites. Oliver Twist and his companions suffered the  ortures of slow starvation for three months: at last they got so voracious and wild with hunger, that one boy, who was tall for his age, and hadn’t been used to that sort of thing (for his father had kept a small cook-shop), hinted darkly to his companions, that unless he had another basin of gruel per diem [each day], he was afraid he might some night happen to eat the boy who slept next him, who happened to be a weakly youth of tender age. He had a wild, hungry eye; and they implicitly believed him. A council was held; lots [objects, such as straws, that would be taken out of a container to make a decision or choice] were cast who should walk up to the master after supper that evening, and ask for more; and it fell to Oliver Twist.\"\n",
        "docs = text.split(\".\")"
      ],
      "metadata": {
        "id": "ch_k8rCzZ0Q8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(docs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S2gKP8J38tka",
        "outputId": "cbc350db-4305-42f8-ccce-64ca4b6e1c5b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['The room in which the boys were fed, was a large stone hall, with a copper [a large, heated copper pot] at one end: out of which the master, dressed in an apron for the purpose, and assisted by one or two women, ladled the gruel [a watery cereal like very thin oatmeal] at mealtimes', ' Of this festive composition each boy had one porringer [small bowl], and no more—except on occasions of great public rejoicing, when he had two ounces and a quarter of bread besides', ' The bowls never wanted washing', ' The boys polished them with their spoons till they shone again; and when they had performed this operation (which never took very long, the spoons being nearly as large as the bowls), they would sit staring at the copper, with such eager eyes, as if they could have devoured the very bricks of which it was composed; employing themselves, meanwhile, in sucking their fingers most assiduously [diligently], with the view of catching up any stray splashes of gruel that  ight have been cast thereon', ' Boys have generally excellent appetites', ' Oliver Twist and his companions suffered the  ortures of slow starvation for three months: at last they got so voracious and wild with hunger, that one boy, who was tall for his age, and hadn’t been used to that sort of thing (for his father had kept a small cook-shop), hinted darkly to his companions, that unless he had another basin of gruel per diem [each day], he was afraid he might some night happen to eat the boy who slept next him, who happened to be a weakly youth of tender age', ' He had a wild, hungry eye; and they implicitly believed him', ' A council was held; lots [objects, such as straws, that would be taken out of a container to make a decision or choice] were cast who should walk up to the master after supper that evening, and ask for more; and it fell to Oliver Twist', '']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.text_splitter import NLTKTextSplitter\n",
        "text_splitter = NLTKTextSplitter()\n",
        "docs = text_splitter.split_text(text)"
      ],
      "metadata": {
        "id": "aPcnMXoo8yBm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(docs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wWeN_GMo9tTe",
        "outputId": "8ff90a78-be74-4eb6-ff8a-08f19b309fed"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['The room in which the boys were fed, was a large stone hall, with a copper [a large, heated copper pot] at one end: out of which the master, dressed in an apron for the purpose, and assisted by one or two women, ladled the gruel [a watery cereal like very thin oatmeal] at mealtimes.\\n\\nOf this festive composition each boy had one porringer [small bowl], and no more—except on occasions of great public rejoicing, when he had two ounces and a quarter of bread besides.\\n\\nThe bowls never wanted washing.\\n\\nThe boys polished them with their spoons till they shone again; and when they had performed this operation (which never took very long, the spoons being nearly as large as the bowls), they would sit staring at the copper, with such eager eyes, as if they could have devoured the very bricks of which it was composed; employing themselves, meanwhile, in sucking their fingers most assiduously [diligently], with the view of catching up any stray splashes of gruel that  ight have been cast thereon.\\n\\nBoys have generally excellent appetites.\\n\\nOliver Twist and his companions suffered the  ortures of slow starvation for three months: at last they got so voracious and wild with hunger, that one boy, who was tall for his age, and hadn’t been used to that sort of thing (for his father had kept a small cook-shop), hinted darkly to his companions, that unless he had another basin of gruel per diem [each day], he was afraid he might some night happen to eat the boy who slept next him, who happened to be a weakly youth of tender age.\\n\\nHe had a wild, hungry eye; and they implicitly believed him.\\n\\nA council was held; lots [objects, such as straws, that would be taken out of a container to make a decision or choice] were cast who should walk up to the master after supper that evening, and ask for more; and it fell to Oliver Twist.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.text_splitter import SpacyTextSplitter\n",
        "text_splitter = SpacyTextSplitter()\n",
        "docs = text_splitter.split_text(text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GvLLDNef-huK",
        "outputId": "10f4b2e8-e4af-442c-9526-2a2d9952e055"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/spacy/pipeline/lemmatizer.py:211: UserWarning: [W108] The rule-based lemmatizer did not find POS annotation for one or more tokens. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
            "  warnings.warn(Warnings.W108)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(docs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "adPcdcjY_F7F",
        "outputId": "caac6c69-034e-45e6-ff86-ef090d0bc498"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['The room in which the boys were fed, was a large stone hall, with a copper [a large, heated copper pot] at one end: out of which the master, dressed in an apron for the purpose, and assisted by one or two women, ladled the gruel\\n\\n[a watery cereal like very thin oatmeal] at mealtimes.\\n\\nOf this festive composition each boy had one porringer [small bowl], and no more—except on occasions of great public rejoicing, when he had two ounces and a quarter of bread besides.\\n\\nThe bowls never wanted washing.\\n\\nThe boys polished them with their spoons till they shone again; and when they had performed this operation (which never took very long, the spoons being nearly as large as the bowls), they would sit staring at the copper, with such eager eyes, as if they could have devoured the very bricks of which it was composed; employing themselves, meanwhile, in sucking their fingers most assiduously\\n\\n[diligently], with the view of catching up any stray splashes of gruel that  ight have been cast thereon.\\n\\nBoys have generally excellent appetites.\\n\\nOliver Twist and his companions suffered the  ortures of slow starvation for three months: at last they got so voracious and wild with hunger, that one boy, who was tall for his age, and hadn’t been used to that sort of thing (for his father had kept a small cook-shop), hinted darkly to his companions, that unless he had another basin of gruel per diem [each day], he was afraid he might some night happen to eat the boy who slept next him, who happened to be a weakly youth of tender age.\\n\\nHe had a wild, hungry eye; and they implicitly believed him.\\n\\nA council was held;\\n\\nlots [objects, such as straws, that would be taken out of a container to make a decision or choice] were cast who should walk up to the master after supper that evening, and ask for more; and it fell to Oliver Twist.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "text_splitter = RecursiveCharacterTextSplitter(chunk_size = 256,chunk_overlap = 20)\n",
        "docs = text_splitter.create_documents([text])"
      ],
      "metadata": {
        "id": "9fehAs23_Sxe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "docs"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GQOsgBaDY767",
        "outputId": "5b42eafa-7a80-4fc3-edf9-b4418e8b8daa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Document(page_content='The room in which the boys were fed, was a large stone hall, with a copper [a large, heated copper pot] at one end: out of which the master, dressed in an apron for the purpose, and assisted by one or two women, ladled the gruel [a watery cereal like very'),\n",
              " Document(page_content='cereal like very thin oatmeal] at mealtimes. Of this festive composition each boy had one porringer [small bowl], and no more—except on occasions of great public rejoicing, when he had two ounces and a quarter of bread besides. The bowls never wanted'),\n",
              " Document(page_content='bowls never wanted washing. The boys polished them with their spoons till they shone again; and when they had performed this operation (which never took very long, the spoons being nearly as large as the bowls), they would sit staring at the copper, with'),\n",
              " Document(page_content='at the copper, with such eager eyes, as if they could have devoured the very bricks of which it was composed; employing themselves, meanwhile, in sucking their fingers most assiduously [diligently], with the view of catching up any stray splashes of gruel'),\n",
              " Document(page_content='splashes of gruel that  ight have been cast thereon. Boys have generally excellent appetites. Oliver Twist and his companions suffered the  ortures of slow starvation for three months: at last they got so voracious and wild with hunger, that one boy, who'),\n",
              " Document(page_content='that one boy, who was tall for his age, and hadn’t been used to that sort of thing (for his father had kept a small cook-shop), hinted darkly to his companions, that unless he had another basin of gruel per diem [each day], he was afraid he might some'),\n",
              " Document(page_content='he might some night happen to eat the boy who slept next him, who happened to be a weakly youth of tender age. He had a wild, hungry eye; and they implicitly believed him. A council was held; lots [objects, such as straws, that would be taken out of a'),\n",
              " Document(page_content='be taken out of a container to make a decision or choice] were cast who should walk up to the master after supper that evening, and ask for more; and it fell to Oliver Twist.')]"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "w6_qhTfOY9TZ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}